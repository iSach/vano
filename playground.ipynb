{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:39:38.795148Z",
     "start_time": "2023-12-04T11:39:38.789532Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as topt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# torch distribs\n",
    "import torch.distributions as dists\n",
    "\n",
    "from neuralop.models import FNO\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'mps'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Experiments</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gaussian Random Fields (GRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sach/miniconda3/envs/deeplearning/lib/python3.9/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1699947508764/work/aten/src/ATen/native/TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/sach/Development/Python/VANO/playground.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# gen & plot\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m grid \u001b[39m=\u001b[39m gaussian_random_field((\u001b[39m128\u001b[39;49m, \u001b[39m128\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m plot_grid(grid, title\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mGaussian Random Field\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/sach/Development/Python/VANO/playground.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m grid \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack([x, y], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m grid \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m grid \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39;49mrepeat(\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m grid \u001b[39m=\u001b[39m grid \u001b[39m/\u001b[39m scale\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m grid \u001b[39m=\u001b[39m grid \u001b[39m-\u001b[39m grid\u001b[39m.\u001b[39mmean()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of dimensions of repeat dims can not be smaller than number of dimensions of tensor"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "# GRF (TODO)\n",
    "# Is it like Gaussian Processes? In the VANO paper, it just seems like functions where each f(x_i) is a Gaussian random variable, but they are linked so that it is \"continuous\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 2D Gaussian Densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:39:41.729363Z",
     "start_time": "2023-12-04T11:39:41.709401Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=32, input_dim=2, output_dim=1, device='cpu'):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.activ = nn.GELU()\n",
    "\n",
    "        # Input: [output_dim, 48, 48]\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Conv2d(output_dim, 8, 2),        # [8, 47, 47]\n",
    "            self.activ,\n",
    "            nn.Conv2d(8, 16, 2),                # [16, 46, 46]\n",
    "            self.activ,\n",
    "            nn.MaxPool2d(2),                    # [16, 23, 23]\n",
    "            nn.Conv2d(16, 32, 2),               # [32, 22, 22]\n",
    "            self.activ,\n",
    "            nn.Conv2d(32, 64, 2),               # [64, 21, 21]\n",
    "            self.activ,\n",
    "            nn.MaxPool2d(2),                    # [64, 10, 10]\n",
    "            nn.Flatten(),                       # [64 * 10 * 10]\n",
    "            nn.Linear(64 * 10 * 10, 256),       # [256]\n",
    "            self.activ,\n",
    "            nn.Linear(256, 128),                # [128]\n",
    "            self.activ,\n",
    "            nn.Linear(128, 2 * self.latent_dim) # [2 * latent_dim]\n",
    "        )\n",
    "\n",
    "    def forward(self, u):\n",
    "        out = self.seq(u)\n",
    "        mean = out[:, :self.latent_dim]\n",
    "        logvar = out[:, self.latent_dim:]\n",
    "\n",
    "        eps = torch.randn(u.shape[0], self.latent_dim, device=u.device)\n",
    "        z = mean + eps * torch.exp(0.5 * logvar)\n",
    "\n",
    "        return mean, logvar, z\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=32, input_dim=2, output_dim=1, device='cpu'):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # (original) NeRF-like architecture\n",
    "        self.mlp_x = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32)\n",
    "        )\n",
    "        self.mlp_z = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, 2 * self.latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * self.latent_dim, 2 * self.latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * self.latent_dim, 32)\n",
    "        )\n",
    "        self.joint_mlp = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        \"\"\"\n",
    "        Computes u(x) by conditioning on z, a latent representation of u.\n",
    "\n",
    "        Args:\n",
    "            x: (batch_size, input_dim) tensor of spatial locations\n",
    "            z: (batch_size, latent_dim) tensor of latent representations\n",
    "        \"\"\"\n",
    "        x = self.mlp_x(x)\n",
    "        z = self.mlp_z(z)\n",
    "        # z is [32, 32], reshape to [32, 48, 48, 32]\n",
    "        z = z.view(-1, 1, 1, 32).expand(-1, 48, 48, -1)\n",
    "        xz = torch.cat([x, z], dim=-1)\n",
    "        xz = self.joint_mlp(xz)\n",
    "\n",
    "        return xz\n",
    "\n",
    "\n",
    "class VANO(nn.Module):\n",
    "    def __init__(self, latent_dim=32, input_dim=2, output_dim=1, device='cpu'):\n",
    "        super(VANO, self).__init__()\n",
    "    \n",
    "        self.encoder = Encoder(latent_dim, input_dim, output_dim, device)\n",
    "        self.decoder = Decoder(latent_dim, input_dim, output_dim, device)\n",
    "\n",
    "        ls = torch.linspace(0, 1, 48).to(device)\n",
    "        self.grid = torch.stack(torch.meshgrid(ls, ls), dim=-1).unsqueeze(0)\n",
    "\n",
    "    def forward(self, u):\n",
    "        z, mean, logvar = self.encoder(u)\n",
    "        grids = self.grid.expand(u.shape[0], *self.grid.shape[1:])\n",
    "        u_pred = self.decoder(grids, z)\n",
    "\n",
    "        return mean, logvar, z, u_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:39:46.169529Z",
     "start_time": "2023-12-04T11:39:44.372007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 32]) torch.Size([5, 32]) torch.Size([5, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      9\u001b[0m dec \u001b[38;5;241m=\u001b[39m Decoder()\n\u001b[0;32m---> 10\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mdec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(out\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 84\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# z is [32, 32], reshape to [32, 48, 48, 32]\u001b[39;00m\n\u001b[1;32m     83\u001b[0m z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m48\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m xz \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m xz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoint_mlp(xz)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xz\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 4"
     ]
    }
   ],
   "source": [
    "enc = Encoder()\n",
    "\n",
    "u = torch.randn(5, 1, 48, 48)\n",
    "\n",
    "mean, logvar, z = enc(u)\n",
    "print(z.shape, mean.shape, logvar.shape)\n",
    "\n",
    "x = torch.rand(5, 2)\n",
    "dec = Decoder()\n",
    "out = dec(x, z)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T11:39:48.217513Z",
     "start_time": "2023-12-04T11:39:46.374350Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sach/miniconda3/envs/dl/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392020195/work/aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PyTorch is not linked with support for mps devices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m N_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m\n\u001b[1;32m     24\u001b[0m N_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m---> 26\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mgen_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m test_data \u001b[38;5;241m=\u001b[39m gen_datasets(N_test, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mTensorDataset(\u001b[38;5;241m*\u001b[39mtrain_data)\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mgen_datasets\u001b[0;34m(N, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([grid] \u001b[38;5;241m*\u001b[39m N, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([dists\u001b[38;5;241m.\u001b[39mMultivariateNormal(\n\u001b[1;32m     16\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor([mu_x[i], mu_y[i]]),\n\u001b[1;32m     17\u001b[0m     covariance_matrix\u001b[38;5;241m=\u001b[39m(sigma[i]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     18\u001b[0m     )\u001b[38;5;241m.\u001b[39mlog_prob(grid) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y\u001b[38;5;241m.\u001b[39mexp()\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PyTorch is not linked with support for mps devices"
     ]
    }
   ],
   "source": [
    "def gen_datasets(N=1, device='cpu'):\n",
    "    \"\"\"\n",
    "    Creates N 2D gaussian pdfs.\n",
    "    \"\"\"\n",
    "    mu_x = dists.Uniform(0, 1).sample((N,))\n",
    "    mu_y = dists.Uniform(0, 1).sample((N,))\n",
    "\n",
    "    # Std dev\n",
    "    sigma = 0.01 + dists.Uniform(0, 0.1).sample((N,))\n",
    "    \n",
    "    dim_range = torch.linspace(0, 1, 48)\n",
    "    grid = torch.stack(torch.meshgrid(dim_range, dim_range), dim=-1)\n",
    "\n",
    "    x = torch.stack([grid] * N, dim=0)\n",
    "    y = torch.stack([dists.MultivariateNormal(\n",
    "        torch.tensor([mu_x[i], mu_y[i]]),\n",
    "        covariance_matrix=(sigma[i]**2 * torch.eye(2))\n",
    "        ).log_prob(grid) for i in range(N)], dim=0)\n",
    "\n",
    "    return x.to(device), y.exp().to(device)\n",
    "\n",
    "# Generate datasets\n",
    "N_train = 2048\n",
    "N_test = 32\n",
    "\n",
    "train_data = gen_datasets(N_train, device='mps')\n",
    "test_data = gen_datasets(N_test, device='mps')\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(*train_data)\n",
    "test_dataset = torch.utils.data.TensorDataset(*test_data)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Grid size\", train_data[0].shape)\n",
    "print(\"Function size\", train_data[1].shape)\n",
    "\n",
    "# Plot a grid with 10x10 sample functions\n",
    "example_fcts = train_data[1][:100].reshape(10, 10, 48, 48).cpu().numpy()\n",
    "grid_size = 5\n",
    "fig, ax = plt.subplots(grid_size, grid_size, figsize=(grid_size, grid_size))\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        data = example_fcts[i, j]\n",
    "        ax[i, j].imshow(data)\n",
    "        ax[i, j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bafe491490347309fbe17ac816f4d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb711c821a25430cad7e4f08a2b442d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cb6926b49e423d8479916adafaa6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sach/Development/Python/VANO/playground.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()            \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#X11sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39;49mitem())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#X11sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sach/Development/Python/VANO/playground.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     lr_scheduler\u001b[39m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'mps'\n",
    "\n",
    "# Training\n",
    "vano = VANO(device=device).to(device)\n",
    "vano.train()\n",
    "\n",
    "# Parameters:\n",
    "S = 4  # Monte Carlo samples for evaluating reconstruction loss in ELBO (E_q(z | x) [log p(x | z)])\n",
    "beta = 10e-5  # Weighting of KL divergence in ELBO\n",
    "batch_size = 32\n",
    "#num_iters = 20_000\n",
    "num_iters = 500\n",
    "\n",
    "# Exponential decay of every 1000 iterations by 0.9\n",
    "lr = 1e-3\n",
    "lr_decay = 0.9\n",
    "lr_decay_every = 1000\n",
    "optimizer = topt.Adam(vano.parameters(), lr=lr)\n",
    "lr_scheduler = topt.lr_scheduler.StepLR(optimizer, step_size=lr_decay_every, gamma=lr_decay)\n",
    "\n",
    "losses = []\n",
    "\n",
    "step = 0\n",
    "num_epochs = num_iters // len(train_loader)\n",
    "for epoch in (epoch_bar := tqdm(range(num_epochs), position=0, leave=True, desc=\"Epochs\")):\n",
    "    epoch_bar.set_description(f\"Epoch {epoch}\")\n",
    "    for grid, u in (iter_bar := tqdm(train_loader, position=1, leave=False)):\n",
    "        iter_bar.set_description(f\"Step {step}\")\n",
    "\n",
    "        #grid, u = grid.to(device), u.to(device)\n",
    "        \n",
    "        mu, logvar, z, u_hat = vano(u.view(-1, 1, 48, 48))\n",
    "        u_hat = u_hat.squeeze()\n",
    "\n",
    "        u, u_hat = u.flatten(1), u_hat.flatten(1)\n",
    "\n",
    "        # ELBO = E_p(eps)[log p(x | z=g(eps, x))] - KL(q(z | x) || p(z))\n",
    "        loss = F.mse_loss(u_hat, u, reduction='none').sum(axis=1).mean()\n",
    "        loss += beta * (0.5 * (mu ** 2 + logvar.exp() - logvar - 1).sum(axis=1).mean())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()            \n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Phase Separation in Cahn-Hilliard Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interferometric Synthetic Aperture Radar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
