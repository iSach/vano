{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as topt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from neuralop.models import FNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=64, input_dim=2, output_dim=1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.fno = FNO()\n",
    "\n",
    "    def forward(self, u):\n",
    "\n",
    "        eps = torch.randn(u.shape[0], self.latent_dim, device=u.device)\n",
    "        mean = ...\n",
    "        logvar = ...\n",
    "\n",
    "        z = mean + eps * torch.exp(0.5 * logvar)\n",
    "\n",
    "        return z, mean, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=64, input_dim=2, output_dim=1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # (original) NeRF-like architecture\n",
    "        self.mlp_x = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 32)\n",
    "        )\n",
    "        self.mlp_z = nn.Sequential(\n",
    "            nn.Linear(self.latent_dim, 2 * self.latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * self.latent_dim, 2 * self.latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2 * self.latent_dim, 32)\n",
    "        )\n",
    "        self.joint_mlp = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        \"\"\"\n",
    "        Computes u(x) by conditioning on z, a latent representation of u.\n",
    "\n",
    "        Args:\n",
    "            x: (batch_size, input_dim) tensor of spatial locations\n",
    "            z: (batch_size, latent_dim) tensor of latent representations\n",
    "        \"\"\"\n",
    "        x = self.mlp_x(x)\n",
    "        z = self.mlp_z(z)\n",
    "        xz = torch.cat([x, z], dim=1)\n",
    "\n",
    "        return self.joint_mlp(xz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
